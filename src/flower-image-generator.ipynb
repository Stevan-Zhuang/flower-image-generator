{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","execution_count":null,"source":["import os\r\n","import argparse\r\n","\r\n","import torch\r\n","from pl_bolts.models.gans import DCGAN\r\n","from torch.utils.data import DataLoader\r\n","from torchvision.datasets import ImageFolder\r\n","from torchvision import transforms as T\r\n","from torchvision.utils import make_grid\r\n","import pytorch_lightning as pl\r\n","from pytorch_lightning import seed_everything\r\n","\r\n","import numpy as np\r\n","import matplotlib.pyplot as plt\r\n","\r\n","from typing import Optional, List, Any"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["seed_everything(6)"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["config = argparse.Namespace(\r\n","    gpu=True,\r\n","    data_dir=\"../input/pytorch-challange-flower-dataset/dataset\",\r\n","    n_epochs=40,\r\n","    batch_size=128,\r\n","    \r\n","    min_image_size=500,\r\n","    image_size=64,\r\n","    n_channels=3,\r\n",")"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["class ImageDataModule(pl.LightningDataModule):\r\n","    def __init__(self, data_dir: str, min_image_size: str,\r\n","                 image_size: Optional[int] = 64,\r\n","                 batch_size: Optional[int] = 1) -> None:\r\n","        super(ImageDataModule, self).__init__()\r\n","        \r\n","        self.data_dir = data_dir\r\n","        self.batch_size = batch_size\r\n","        self.image_size = image_size\r\n","\r\n","    def setup(self, stage: Optional[str] = None) -> None:\r\n","        pipeline = T.Compose([\r\n","            T.CenterCrop(500),\r\n","            T.Resize(self.image_size),\r\n","            T.ToTensor(),\r\n","            T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\r\n","        ])\r\n","        self.train_dataset = ImageFolder(\r\n","            self.data_dir, transform=pipeline\r\n","        )\r\n","\r\n","    def train_dataloader(self) -> DataLoader:\r\n","        return DataLoader(self.train_dataset, batch_size=self.batch_size,\r\n","                          shuffle=True)"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["def demo_single(model: torch.nn.Module) -> None:\r\n","    \"\"\"Create a demo of a single image generated by model.\"\"\"\r\n","    single = (model(torch.rand(1, 100)).squeeze(0) * 0.5 + 0.5).detach()\r\n","    plt.imshow(single.permute(1, 2, 0))\r\n","    plt.show()"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["def demo_grid(model: torch.nn.Module) -> None:\r\n","    \"\"\"Create a 3 x 5 demo of images generated by model.\"\"\"\r\n","    grid = make_grid(model(torch.randn(15, 100)).detach(), nrow=5, normalize=True)\r\n","    plt.imshow(grid.permute(1, 2, 0))\r\n","    plt.show()"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["flower_dm = ImageDataModule(config.data_dir, config.min_image_size,\r\n","                            config.image_size, config.batch_size)\r\n","\r\n","model = DCGAN(image_channels=config.n_channels)\r\n","\r\n","trainer = pl.Trainer(\r\n","    gpus=1 if config.gpu else 0,\r\n","    max_epochs=config.n_epochs,\r\n",")"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["trainer.fit(model, datamodule=flower_dm)\r\n","\r\n","demo_single(model)\r\n","demo_grid(model)"],"outputs":[],"metadata":{"trusted":true}}]}